{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AbGKvO3ibHlq"
      },
      "outputs": [],
      "source": [
        "!pip install datasets trl torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO_TldBEa5Cl"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "dataset = load_dataset(\"trl-lib/tldr\", split=\"train\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UChG04Wa_S0"
      },
      "outputs": [],
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "\n",
        "def reward_len(completions, **kwargs):\n",
        "    return [-abs(20 - len(completion)) for completion in completions]\n",
        "\n",
        "\n",
        "training_args = GRPOConfig(output_dir=\"Qwen-Distill-1.5B-GRPO\", logging_steps=10)\n",
        "trainer = GRPOTrainer(\n",
        "    model=\"Qwen/Qwen2-0.5B\",\n",
        "    reward_funcs=reward_len,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        ")\n",
        "trainer.model.device_map=\"auto\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QrLmm4ha_QY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for name, module in trainer.model.named_modules():\n",
        "    print(f\"name='{name}'\")\n",
        "\n",
        "\n",
        "def print_total_parameters(model):\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "    print(f\"Total parameters in the original model: {all_param}\")\n",
        "\n",
        "\n",
        "print_total_parameters(trainer.model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Chl_oSca_OP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "whitelist_layer_patterns = [\n",
        "    \"model.embed_tokens\",  # Embedding layer - ALWAYS trainable - very big\n",
        "    \"model.layers.0\",  # First Transformer Layer Block - KEEP trainable as requested\n",
        "    \"model.norm\",  # Final LayerNorm - Often trainable\n",
        "    \"lm_head\",  # Language Model Head - ALWAYS trainable - very big\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Freeze all parameters EXCEPT those in the whitelist\n",
        "for n, p in trainer.model.named_parameters():\n",
        "    p.requires_grad = False # Freeze all layers by default\n",
        "    for layer_pattern in whitelist_layer_patterns:\n",
        "        if layer_pattern in n: # Check if the current layer name matches any whitelist pattern\n",
        "            if p.dtype in [torch.float16, torch.float32, torch.bfloat16, torch.complex64, torch.complex128]: # ADDED dtype check!\n",
        "                p.requires_grad = True # Unfreeze if it's in the whitelist AND it's a float type\n",
        "            break # No need to check other patterns if already whitelisted\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1tE7Nx-a_L3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Verification - Count trainable parameters. Should be significantly less than full model.\n",
        "def print_trainable_parameters(model):\n",
        "  trainable_params = 0\n",
        "  all_param = 0\n",
        "  for _, param in model.named_parameters():\n",
        "      all_param += param.numel()\n",
        "      if param.requires_grad:\n",
        "          trainable_params += param.numel()\n",
        "  print(\n",
        "      f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "  )\n",
        "print_trainable_parameters(trainer.model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XEts-dSa_Jc"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
